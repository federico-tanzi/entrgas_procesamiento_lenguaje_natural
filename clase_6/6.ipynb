{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pfa39F4lsLf3",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<img src=\"https://github.com/hernancontigiani/ceia_memorias_especializacion/raw/master/Figures/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n",
    "\n",
    "\n",
    "# Procesamiento de lenguaje natural\n",
    "## LSTM Bot QA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZqO0PRcFsPTe",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Datos\n",
    "El objecto es utilizar datos disponibles del challenge ConvAI2 (Conversational Intelligence Challenge 2) de conversaciones en inglés. Se construirá un BOT para responder a preguntas del usuario (QA).\\\n",
    "[LINK](http://convai.io/data/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "bDFC0I3j9oFD",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade --no-cache-dir gdown --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "cq3YXak9sGHd",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.utils import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Activation, Dropout, Dense\n",
    "from keras.layers import Flatten, LSTM, SimpleRNN\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "RHNkUaPp6aYq",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1awUxYwImF84MIT5-jCaYAPe2QwSgS1hN&export=download\n",
      "To: /Users/federicotanzi/posgrado/entregas_procesamiento_lenguaje_natural/clase_6/data_volunteers.json\n",
      "100%|██████████| 2.58M/2.58M [00:00<00:00, 18.2MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Descargar la carpeta de dataset\n",
    "import os\n",
    "import gdown\n",
    "if os.access('data_volunteers.json', os.F_OK) is False:\n",
    "    url = 'https://drive.google.com/uc?id=1awUxYwImF84MIT5-jCaYAPe2QwSgS1hN&export=download'\n",
    "    output = 'data_volunteers.json'\n",
    "    gdown.download(url, output, quiet=False)\n",
    "else:\n",
    "    print(\"El dataset ya se encuentra descargado\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "WZy1-wgG-Rp7",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# dataset_file\n",
    "import json\n",
    "\n",
    "text_file = \"data_volunteers.json\"\n",
    "with open(text_file) as f:\n",
    "    data = json.load(f) # la variable data será un diccionario\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ue5qd54S-eew",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "dict_keys(['dialog', 'start_time', 'end_time', 'bot_profile', 'user_profile', 'eval_score', 'profile_match', 'participant1_id', 'participant2_id'])"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Observar los campos disponibles en cada linea del dataset\n",
    "data[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "jHBRAXPl-3dz",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de rows utilizadas: 6033\n"
     ]
    }
   ],
   "source": [
    "chat_in = []\n",
    "chat_out = []\n",
    "\n",
    "input_sentences = []\n",
    "output_sentences = []\n",
    "output_sentences_inputs = []\n",
    "max_len = 30\n",
    "\n",
    "def clean_text(txt):\n",
    "    txt = txt.lower()    \n",
    "    txt.replace(\"\\'d\", \" had\")\n",
    "    txt.replace(\"\\'s\", \" is\")\n",
    "    txt.replace(\"\\'m\", \" am\")\n",
    "    txt.replace(\"don't\", \"do not\")\n",
    "    txt = re.sub(r'\\W+', ' ', txt)\n",
    "    \n",
    "    return txt\n",
    "\n",
    "for line in data:\n",
    "    for i in range(len(line['dialog'])-1):\n",
    "        # vamos separando el texto en \"preguntas\" (chat_in)\n",
    "        # y \"respuestas\" (chat_out)\n",
    "        chat_in = clean_text(line['dialog'][i]['text'])\n",
    "        chat_out = clean_text(line['dialog'][i+1]['text'])\n",
    "\n",
    "        if len(chat_in) >= max_len or len(chat_out) >= max_len:\n",
    "            continue\n",
    "\n",
    "        input_sentence, output = chat_in, chat_out\n",
    "        \n",
    "        # output sentence (decoder_output) tiene <eos>\n",
    "        output_sentence = output + ' <eos>'\n",
    "        # output sentence input (decoder_input) tiene <sos>\n",
    "        output_sentence_input = '<sos> ' + output\n",
    "\n",
    "        input_sentences.append(input_sentence)\n",
    "        output_sentences.append(output_sentence)\n",
    "        output_sentences_inputs.append(output_sentence_input)\n",
    "\n",
    "print(\"Cantidad de rows utilizadas:\", len(input_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "07L1qj8pC_l6",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "('hi how are you ', 'not bad and you  <eos>', '<sos> not bad and you ')"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sentences[1], output_sentences[1], output_sentences_inputs[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8P-ynUNP5xp6",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2 - Preprocesamiento\n",
    "Realizar el preprocesamiento necesario para obtener:\n",
    "- word2idx_inputs, max_input_len\n",
    "- word2idx_outputs, max_out_len, num_words_output\n",
    "- encoder_input_sequences, decoder_output_sequences, decoder_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "MAX_VOCAB_SIZE = 8000"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palabras en el vocabulario: 1799\n",
      "Sentencia de entrada más larga: 9\n"
     ]
    }
   ],
   "source": [
    "input_tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE)\n",
    "input_tokenizer.fit_on_texts(input_sentences)\n",
    "input_integer_seq = input_tokenizer.texts_to_sequences(input_sentences)\n",
    "\n",
    "word2idx_inputs = input_tokenizer.word_index\n",
    "print(\"Palabras en el vocabulario:\", len(word2idx_inputs))\n",
    "\n",
    "max_input_len = max(len(sen) for sen in input_integer_seq)\n",
    "print(\"Sentencia de entrada más larga:\", max_input_len)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Palabras en el vocabulario: 1806\n",
      "Sentencia de salida más larga: 10\n"
     ]
    }
   ],
   "source": [
    "# A los filtros de símbolos del Tokenizer agregamos el \"¿\",\n",
    "# sacamos los \"<>\" para que no afectar nuestros tokens\n",
    "output_tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE, filters='!\"#$%&()*+,-./:;=¿?@[\\\\]^_`{|}~\\t\\n')\n",
    "output_tokenizer.fit_on_texts([\"<sos>\", \"<eos>\"] + output_sentences)\n",
    "output_integer_seq = output_tokenizer.texts_to_sequences(output_sentences)\n",
    "output_input_integer_seq = output_tokenizer.texts_to_sequences(output_sentences_inputs)\n",
    "\n",
    "word2idx_outputs = output_tokenizer.word_index\n",
    "print(\"Palabras en el vocabulario:\", len(word2idx_outputs))\n",
    "\n",
    "num_words_output = min(len(word2idx_outputs) + 1, MAX_VOCAB_SIZE) # Se suma 1 por el primer <sos>\n",
    "max_out_len = max(len(sen) for sen in output_integer_seq)\n",
    "print(\"Sentencia de salida más larga:\", max_out_len)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de rows del dataset: 6033\n",
      "encoder_input_sequences shape: (6033, 9)\n",
      "decoder_input_sequences shape: (6033, 10)\n"
     ]
    }
   ],
   "source": [
    "print(\"Cantidad de rows del dataset:\", len(input_integer_seq))\n",
    "\n",
    "encoder_input_sequences = pad_sequences(input_integer_seq, maxlen=max_input_len)\n",
    "print(\"encoder_input_sequences shape:\", encoder_input_sequences.shape)\n",
    "\n",
    "decoder_input_sequences = pad_sequences(output_input_integer_seq, maxlen=max_out_len, padding='post')\n",
    "print(\"decoder_input_sequences shape:\", decoder_input_sequences.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "(6033, 10, 1807)"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "decoder_output_sequences = pad_sequences(output_integer_seq, maxlen=max_out_len, padding='post')\n",
    "decoder_targets = to_categorical(decoder_output_sequences, num_classes=num_words_output)\n",
    "decoder_targets.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_CJIsLBbj6rg",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3 - Preparar los embeddings\n",
    "Utilizar los embeddings de Glove o FastText para transformar los tokens de entrada en vectores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (uriginal): https://drive.google.com/uc?id=1wlDBOrxPq2-3htQ6ryVo7K1XnzLcfh4r&export=download\n",
      "From (redirected): https://drive.google.com/uc?id=1wlDBOrxPq2-3htQ6ryVo7K1XnzLcfh4r&export=download&confirm=t&uuid=7095b823-17d4-49dc-8557-606b562a5ce3\n",
      "To: /Users/federicotanzi/posgrado/entregas_procesamiento_lenguaje_natural/clase_6/gloveembedding.pkl\n",
      "100%|██████████| 525M/525M [00:44<00:00, 11.8MB/s] \n"
     ]
    }
   ],
   "source": [
    "# Descargar los embeddings desde un gogle drive (es la forma más rápida)\n",
    "# NOTA: No hay garantía de que estos links perduren, en caso de que no estén\n",
    "# disponibles descargar de la página oficial como se explica en el siguiente bloque\n",
    "import os\n",
    "import gdown\n",
    "if os.access('gloveembedding.pkl', os.F_OK) is False:\n",
    "    url = 'https://drive.google.com/uc?id=1wlDBOrxPq2-3htQ6ryVo7K1XnzLcfh4r&export=download'\n",
    "    output = 'gloveembedding.pkl'\n",
    "    gdown.download(url, output, quiet=False)\n",
    "else:\n",
    "    print(\"Los embeddings gloveembedding.pkl ya están descargados\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "\n",
    "class WordsEmbeddings(object):\n",
    "    logger = logging.getLogger(__name__)\n",
    "\n",
    "    def __init__(self):\n",
    "        # load the embeddings\n",
    "        words_embedding_pkl = Path(self.PKL_PATH)\n",
    "        if not words_embedding_pkl.is_file():\n",
    "            words_embedding_txt = Path(self.WORD_TO_VEC_MODEL_TXT_PATH)\n",
    "            assert words_embedding_txt.is_file(), 'Words embedding not available'\n",
    "            embeddings = self.convert_model_to_pickle()\n",
    "        else:\n",
    "            embeddings = self.load_model_from_pickle()\n",
    "        self.embeddings = embeddings\n",
    "        # build the vocabulary hashmap\n",
    "        index = np.arange(self.embeddings.shape[0])\n",
    "        # Dicctionarios para traducir de embedding a IDX de la palabra\n",
    "        self.word2idx = dict(zip(self.embeddings['word'], index))\n",
    "        self.idx2word = dict(zip(index, self.embeddings['word']))\n",
    "\n",
    "    def get_words_embeddings(self, words):\n",
    "        words_idxs = self.words2idxs(words)\n",
    "        return self.embeddings[words_idxs]['embedding']\n",
    "\n",
    "    def words2idxs(self, words):\n",
    "        return np.array([self.word2idx.get(word, -1) for word in words])\n",
    "\n",
    "    def idxs2words(self, idxs):\n",
    "        return np.array([self.idx2word.get(idx, '-1') for idx in idxs])\n",
    "\n",
    "    def load_model_from_pickle(self):\n",
    "        self.logger.debug(\n",
    "            'loading words embeddings from pickle {}'.format(\n",
    "                self.PKL_PATH\n",
    "            )\n",
    "        )\n",
    "        max_bytes = 2**28 - 1 # 256MB\n",
    "        bytes_in = bytearray(0)\n",
    "        input_size = os.path.getsize(self.PKL_PATH)\n",
    "        with open(self.PKL_PATH, 'rb') as f_in:\n",
    "            for _ in range(0, input_size, max_bytes):\n",
    "                bytes_in += f_in.read(max_bytes)\n",
    "        embeddings = pickle.loads(bytes_in)\n",
    "        self.logger.debug('words embeddings loaded')\n",
    "        return embeddings\n",
    "\n",
    "    def convert_model_to_pickle(self):\n",
    "        # create a numpy strctured array:\n",
    "        # word     embedding\n",
    "        # U50      np.float32[]\n",
    "        # word_1   a, b, c\n",
    "        # word_2   d, e, f\n",
    "        # ...\n",
    "        # word_n   g, h, i\n",
    "        self.logger.debug(\n",
    "            'converting and loading words embeddings from text file {}'.format(\n",
    "                self.WORD_TO_VEC_MODEL_TXT_PATH\n",
    "            )\n",
    "        )\n",
    "        structure = [('word', np.dtype('U' + str(self.WORD_MAX_SIZE))),\n",
    "                     ('embedding', np.float32, (self.N_FEATURES,))]\n",
    "        structure = np.dtype(structure)\n",
    "        # load numpy array from disk using a generator\n",
    "        with open(self.WORD_TO_VEC_MODEL_TXT_PATH, encoding=\"utf8\") as words_embeddings_txt:\n",
    "            embeddings_gen = (\n",
    "                (line.split()[0], line.split()[1:]) for line in words_embeddings_txt\n",
    "                if len(line.split()[1:]) == self.N_FEATURES\n",
    "            )\n",
    "            embeddings = np.fromiter(embeddings_gen, structure)\n",
    "        # add a null embedding\n",
    "        null_embedding = np.array(\n",
    "            [('null_embedding', np.zeros((self.N_FEATURES,), dtype=np.float32))],\n",
    "            dtype=structure\n",
    "        )\n",
    "        embeddings = np.concatenate([embeddings, null_embedding])\n",
    "        # dump numpy array to disk using pickle\n",
    "        max_bytes = 2**28 - 1 # # 256MB\n",
    "        bytes_out = pickle.dumps(embeddings, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "        with open(self.PKL_PATH, 'wb') as f_out:\n",
    "            for idx in range(0, len(bytes_out), max_bytes):\n",
    "                f_out.write(bytes_out[idx:idx+max_bytes])\n",
    "        self.logger.debug('words embeddings loaded')\n",
    "        return embeddings\n",
    "\n",
    "\n",
    "class GloveEmbeddings(WordsEmbeddings):\n",
    "    WORD_TO_VEC_MODEL_TXT_PATH = 'glove.twitter.27B.50d.txt'\n",
    "    PKL_PATH = 'gloveembedding.pkl'\n",
    "    N_FEATURES = 50\n",
    "    WORD_MAX_SIZE = 60\n",
    "\n",
    "\n",
    "class FasttextEmbeddings(WordsEmbeddings):\n",
    "    WORD_TO_VEC_MODEL_TXT_PATH = 'cc.en.300.vec'\n",
    "    PKL_PATH = 'fasttext.pkl'\n",
    "    N_FEATURES = 300\n",
    "    WORD_MAX_SIZE = 60"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "model_embeddings = GloveEmbeddings()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preparing embedding matrix...\n",
      "number of null word embeddings: 38\n"
     ]
    }
   ],
   "source": [
    "print('preparing embedding matrix...')\n",
    "embed_dim = model_embeddings.N_FEATURES\n",
    "words_not_found = []\n",
    "\n",
    "# word_index provieen del tokenizer\n",
    "\n",
    "nb_words = min(MAX_VOCAB_SIZE, len(word2idx_inputs)) # vocab_size\n",
    "embedding_matrix = np.zeros((nb_words, embed_dim))\n",
    "for word, i in word2idx_inputs.items():\n",
    "    if i >= nb_words:\n",
    "        continue\n",
    "    embedding_vector = model_embeddings.get_words_embeddings(word)[0]\n",
    "    if (embedding_vector is not None) and len(embedding_vector) > 0:\n",
    "\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "    else:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        words_not_found.append(word)\n",
    "\n",
    "print('number of null word embeddings:', np.sum(np.sum(embedding_matrix, axis=1) == 0))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "(1799, 50)"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3vKbhjtIwPgM",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 4 - Entrenar el modelo\n",
    "Entrenar un modelo basado en el esquema encoder-decoder utilizando los datos generados en los puntos anteriores. Utilce como referencias los ejemplos vistos en clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1 Pro\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 9)]          0           []                               \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)           [(None, 10)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 9, 50)        89950       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, 10, 128)      231296      ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " lstm (LSTM)                    [(None, 128),        91648       ['embedding[0][0]']              \n",
      "                                 (None, 128),                                                     \n",
      "                                 (None, 128)]                                                     \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)                  [(None, 10, 128),    131584      ['embedding_1[0][0]',            \n",
      "                                 (None, 128),                     'lstm[0][1]',                   \n",
      "                                 (None, 128)]                     'lstm[0][2]']                   \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 10, 128)      0           ['lstm_1[0][0]']                 \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 10, 1807)     233103      ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 777,581\n",
      "Trainable params: 687,631\n",
      "Non-trainable params: 89,950\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "n_units = 128\n",
    "\n",
    "# define training encoder\n",
    "encoder_inputs = Input(shape=(max_input_len))\n",
    "\n",
    "#encoder_embedding_layer = Embedding(num_words, EMBEDDING_SIZE, weights=[embedding_matrix], input_length=max_input_len)\n",
    "\n",
    "encoder_embedding_layer = Embedding(\n",
    "          input_dim=nb_words,  # definido en el Tokenizador\n",
    "          output_dim=embed_dim,  # dimensión de los embeddings utilizados\n",
    "          input_length=max_input_len, # máxima sentencia de entrada\n",
    "          weights=[embedding_matrix],  # matrix de embeddings\n",
    "          trainable=False)      # marcar como layer no entrenable\n",
    "\n",
    "encoder_inputs_x = encoder_embedding_layer(encoder_inputs)\n",
    "\n",
    "encoder = LSTM(n_units, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs_x)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# define training decoder\n",
    "decoder_inputs = Input(shape=(max_out_len))\n",
    "decoder_embedding_layer = Embedding(input_dim=num_words_output, output_dim=n_units, input_length=max_out_len)\n",
    "decoder_inputs_x = decoder_embedding_layer(decoder_inputs)\n",
    "\n",
    "decoder_lstm = LSTM(n_units, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs_x, initial_state=encoder_states)\n",
    "\n",
    "#Dropout para mejorar el entrenamiento\n",
    "dropout = Dropout(rate=0.8)\n",
    "decoder_outputs = dropout(decoder_outputs)\n",
    "\n",
    "# Dense\n",
    "decoder_dense = Dense(num_words_output, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=\"Adam\", metrics=['accuracy'])\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "encoder_model = Model(encoder_inputs, encoder_states)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "decoder_state_input_h = Input(shape=(n_units,))\n",
    "decoder_state_input_c = Input(shape=(n_units,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_inputs_single = Input(shape=(1,))\n",
    "decoder_inputs_single_x = decoder_embedding_layer(decoder_inputs_single)\n",
    "\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs_single_x, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model([decoder_inputs_single] + decoder_states_inputs, [decoder_outputs] + decoder_states)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-17 12:59:34.370577: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151/151 [==============================] - 11s 38ms/step - loss: 3.1954 - accuracy: 0.5112 - val_loss: 2.2815 - val_accuracy: 0.6134\n",
      "Epoch 2/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 2.1389 - accuracy: 0.6054 - val_loss: 2.1400 - val_accuracy: 0.6329\n",
      "Epoch 3/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 1.9590 - accuracy: 0.6431 - val_loss: 2.0277 - val_accuracy: 0.6614\n",
      "Epoch 4/250\n",
      "151/151 [==============================] - 5s 36ms/step - loss: 1.8226 - accuracy: 0.6781 - val_loss: 1.9407 - val_accuracy: 0.6812\n",
      "Epoch 5/250\n",
      "151/151 [==============================] - 5s 30ms/step - loss: 1.7212 - accuracy: 0.6948 - val_loss: 1.8737 - val_accuracy: 0.6872\n",
      "Epoch 6/250\n",
      "151/151 [==============================] - 4s 28ms/step - loss: 1.6476 - accuracy: 0.7060 - val_loss: 1.8338 - val_accuracy: 0.6954\n",
      "Epoch 7/250\n",
      "151/151 [==============================] - 4s 29ms/step - loss: 1.5903 - accuracy: 0.7140 - val_loss: 1.7974 - val_accuracy: 0.6969\n",
      "Epoch 8/250\n",
      "151/151 [==============================] - 4s 29ms/step - loss: 1.5392 - accuracy: 0.7219 - val_loss: 1.7695 - val_accuracy: 0.7075\n",
      "Epoch 9/250\n",
      "151/151 [==============================] - 4s 27ms/step - loss: 1.5044 - accuracy: 0.7278 - val_loss: 1.7416 - val_accuracy: 0.7090\n",
      "Epoch 10/250\n",
      "151/151 [==============================] - 4s 28ms/step - loss: 1.4662 - accuracy: 0.7309 - val_loss: 1.7247 - val_accuracy: 0.7133\n",
      "Epoch 11/250\n",
      "151/151 [==============================] - 5s 31ms/step - loss: 1.4326 - accuracy: 0.7349 - val_loss: 1.7121 - val_accuracy: 0.7147\n",
      "Epoch 12/250\n",
      "151/151 [==============================] - 4s 27ms/step - loss: 1.4123 - accuracy: 0.7385 - val_loss: 1.6989 - val_accuracy: 0.7186\n",
      "Epoch 13/250\n",
      "151/151 [==============================] - 4s 29ms/step - loss: 1.3874 - accuracy: 0.7403 - val_loss: 1.6864 - val_accuracy: 0.7197\n",
      "Epoch 14/250\n",
      "151/151 [==============================] - 4s 27ms/step - loss: 1.3620 - accuracy: 0.7429 - val_loss: 1.6751 - val_accuracy: 0.7210\n",
      "Epoch 15/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 1.3487 - accuracy: 0.7443 - val_loss: 1.6682 - val_accuracy: 0.7214\n",
      "Epoch 16/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 1.3246 - accuracy: 0.7467 - val_loss: 1.6665 - val_accuracy: 0.7225\n",
      "Epoch 17/250\n",
      "151/151 [==============================] - 4s 28ms/step - loss: 1.3096 - accuracy: 0.7482 - val_loss: 1.6643 - val_accuracy: 0.7248\n",
      "Epoch 18/250\n",
      "151/151 [==============================] - 5s 34ms/step - loss: 1.2948 - accuracy: 0.7491 - val_loss: 1.6556 - val_accuracy: 0.7228\n",
      "Epoch 19/250\n",
      "151/151 [==============================] - 4s 28ms/step - loss: 1.2778 - accuracy: 0.7513 - val_loss: 1.6438 - val_accuracy: 0.7273\n",
      "Epoch 20/250\n",
      "151/151 [==============================] - 4s 28ms/step - loss: 1.2682 - accuracy: 0.7533 - val_loss: 1.6511 - val_accuracy: 0.7282\n",
      "Epoch 21/250\n",
      "151/151 [==============================] - 4s 27ms/step - loss: 1.2555 - accuracy: 0.7537 - val_loss: 1.6458 - val_accuracy: 0.7268\n",
      "Epoch 22/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 1.2436 - accuracy: 0.7558 - val_loss: 1.6438 - val_accuracy: 0.7286\n",
      "Epoch 23/250\n",
      "151/151 [==============================] - 4s 25ms/step - loss: 1.2337 - accuracy: 0.7540 - val_loss: 1.6418 - val_accuracy: 0.7303\n",
      "Epoch 24/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 1.2236 - accuracy: 0.7558 - val_loss: 1.6439 - val_accuracy: 0.7283\n",
      "Epoch 25/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 1.2132 - accuracy: 0.7586 - val_loss: 1.6355 - val_accuracy: 0.7302\n",
      "Epoch 26/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 1.2033 - accuracy: 0.7587 - val_loss: 1.6329 - val_accuracy: 0.7298\n",
      "Epoch 27/250\n",
      "151/151 [==============================] - 4s 25ms/step - loss: 1.1895 - accuracy: 0.7607 - val_loss: 1.6329 - val_accuracy: 0.7290\n",
      "Epoch 28/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 1.1836 - accuracy: 0.7614 - val_loss: 1.6320 - val_accuracy: 0.7325\n",
      "Epoch 29/250\n",
      "151/151 [==============================] - 4s 25ms/step - loss: 1.1719 - accuracy: 0.7617 - val_loss: 1.6374 - val_accuracy: 0.7320\n",
      "Epoch 30/250\n",
      "151/151 [==============================] - 4s 25ms/step - loss: 1.1662 - accuracy: 0.7638 - val_loss: 1.6320 - val_accuracy: 0.7305\n",
      "Epoch 31/250\n",
      "151/151 [==============================] - 4s 25ms/step - loss: 1.1554 - accuracy: 0.7624 - val_loss: 1.6305 - val_accuracy: 0.7323\n",
      "Epoch 32/250\n",
      "151/151 [==============================] - 4s 25ms/step - loss: 1.1487 - accuracy: 0.7657 - val_loss: 1.6346 - val_accuracy: 0.7337\n",
      "Epoch 33/250\n",
      "151/151 [==============================] - 4s 27ms/step - loss: 1.1424 - accuracy: 0.7657 - val_loss: 1.6459 - val_accuracy: 0.7325\n",
      "Epoch 34/250\n",
      "151/151 [==============================] - 4s 28ms/step - loss: 1.1308 - accuracy: 0.7677 - val_loss: 1.6483 - val_accuracy: 0.7316\n",
      "Epoch 35/250\n",
      "151/151 [==============================] - 4s 27ms/step - loss: 1.1260 - accuracy: 0.7668 - val_loss: 1.6441 - val_accuracy: 0.7326\n",
      "Epoch 36/250\n",
      "151/151 [==============================] - 4s 28ms/step - loss: 1.1203 - accuracy: 0.7671 - val_loss: 1.6474 - val_accuracy: 0.7307\n",
      "Epoch 37/250\n",
      "151/151 [==============================] - 5s 34ms/step - loss: 1.1069 - accuracy: 0.7694 - val_loss: 1.6557 - val_accuracy: 0.7324\n",
      "Epoch 38/250\n",
      "151/151 [==============================] - 4s 29ms/step - loss: 1.1006 - accuracy: 0.7696 - val_loss: 1.6449 - val_accuracy: 0.7341\n",
      "Epoch 39/250\n",
      "151/151 [==============================] - 4s 29ms/step - loss: 1.0937 - accuracy: 0.7711 - val_loss: 1.6583 - val_accuracy: 0.7333\n",
      "Epoch 40/250\n",
      "151/151 [==============================] - 5s 36ms/step - loss: 1.0903 - accuracy: 0.7703 - val_loss: 1.6503 - val_accuracy: 0.7347\n",
      "Epoch 41/250\n",
      "151/151 [==============================] - 5s 31ms/step - loss: 1.0823 - accuracy: 0.7722 - val_loss: 1.6522 - val_accuracy: 0.7324\n",
      "Epoch 42/250\n",
      "151/151 [==============================] - 4s 29ms/step - loss: 1.0786 - accuracy: 0.7720 - val_loss: 1.6563 - val_accuracy: 0.7333\n",
      "Epoch 43/250\n",
      "151/151 [==============================] - 4s 27ms/step - loss: 1.0705 - accuracy: 0.7726 - val_loss: 1.6558 - val_accuracy: 0.7331\n",
      "Epoch 44/250\n",
      "151/151 [==============================] - 5s 32ms/step - loss: 1.0659 - accuracy: 0.7743 - val_loss: 1.6575 - val_accuracy: 0.7361\n",
      "Epoch 45/250\n",
      "151/151 [==============================] - 4s 30ms/step - loss: 1.0572 - accuracy: 0.7750 - val_loss: 1.6737 - val_accuracy: 0.7343\n",
      "Epoch 46/250\n",
      "151/151 [==============================] - 5s 34ms/step - loss: 1.0542 - accuracy: 0.7755 - val_loss: 1.6665 - val_accuracy: 0.7341\n",
      "Epoch 47/250\n",
      "151/151 [==============================] - 6s 37ms/step - loss: 1.0475 - accuracy: 0.7765 - val_loss: 1.6652 - val_accuracy: 0.7342\n",
      "Epoch 48/250\n",
      "151/151 [==============================] - 4s 29ms/step - loss: 1.0420 - accuracy: 0.7763 - val_loss: 1.6690 - val_accuracy: 0.7344\n",
      "Epoch 49/250\n",
      "151/151 [==============================] - 4s 27ms/step - loss: 1.0375 - accuracy: 0.7771 - val_loss: 1.6714 - val_accuracy: 0.7327\n",
      "Epoch 50/250\n",
      "151/151 [==============================] - 4s 27ms/step - loss: 1.0323 - accuracy: 0.7785 - val_loss: 1.6864 - val_accuracy: 0.7341\n",
      "Epoch 51/250\n",
      "151/151 [==============================] - 4s 27ms/step - loss: 1.0313 - accuracy: 0.7778 - val_loss: 1.6727 - val_accuracy: 0.7352\n",
      "Epoch 52/250\n",
      "151/151 [==============================] - 4s 27ms/step - loss: 1.0248 - accuracy: 0.7776 - val_loss: 1.6994 - val_accuracy: 0.7358\n",
      "Epoch 53/250\n",
      "151/151 [==============================] - 4s 27ms/step - loss: 1.0170 - accuracy: 0.7794 - val_loss: 1.6898 - val_accuracy: 0.7355\n",
      "Epoch 54/250\n",
      "151/151 [==============================] - 4s 27ms/step - loss: 1.0154 - accuracy: 0.7797 - val_loss: 1.6948 - val_accuracy: 0.7362\n",
      "Epoch 55/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 1.0083 - accuracy: 0.7818 - val_loss: 1.6890 - val_accuracy: 0.7353\n",
      "Epoch 56/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 1.0059 - accuracy: 0.7810 - val_loss: 1.7153 - val_accuracy: 0.7360\n",
      "Epoch 57/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.9990 - accuracy: 0.7821 - val_loss: 1.7061 - val_accuracy: 0.7352\n",
      "Epoch 58/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.9956 - accuracy: 0.7811 - val_loss: 1.7007 - val_accuracy: 0.7345\n",
      "Epoch 59/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.9909 - accuracy: 0.7826 - val_loss: 1.7076 - val_accuracy: 0.7360\n",
      "Epoch 60/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.9861 - accuracy: 0.7846 - val_loss: 1.7208 - val_accuracy: 0.7374\n",
      "Epoch 61/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.9815 - accuracy: 0.7844 - val_loss: 1.7220 - val_accuracy: 0.7370\n",
      "Epoch 62/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.9808 - accuracy: 0.7833 - val_loss: 1.7322 - val_accuracy: 0.7360\n",
      "Epoch 63/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.9717 - accuracy: 0.7854 - val_loss: 1.7304 - val_accuracy: 0.7362\n",
      "Epoch 64/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.9681 - accuracy: 0.7869 - val_loss: 1.7321 - val_accuracy: 0.7355\n",
      "Epoch 65/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.9652 - accuracy: 0.7868 - val_loss: 1.7267 - val_accuracy: 0.7371\n",
      "Epoch 66/250\n",
      "151/151 [==============================] - 6s 37ms/step - loss: 0.9646 - accuracy: 0.7875 - val_loss: 1.7502 - val_accuracy: 0.7344\n",
      "Epoch 67/250\n",
      "151/151 [==============================] - 5s 30ms/step - loss: 0.9605 - accuracy: 0.7873 - val_loss: 1.7340 - val_accuracy: 0.7374\n",
      "Epoch 68/250\n",
      "151/151 [==============================] - 4s 27ms/step - loss: 0.9569 - accuracy: 0.7864 - val_loss: 1.7510 - val_accuracy: 0.7370\n",
      "Epoch 69/250\n",
      "151/151 [==============================] - 4s 27ms/step - loss: 0.9537 - accuracy: 0.7864 - val_loss: 1.7491 - val_accuracy: 0.7391\n",
      "Epoch 70/250\n",
      "151/151 [==============================] - 4s 27ms/step - loss: 0.9454 - accuracy: 0.7893 - val_loss: 1.7607 - val_accuracy: 0.7351\n",
      "Epoch 71/250\n",
      "151/151 [==============================] - 4s 28ms/step - loss: 0.9446 - accuracy: 0.7895 - val_loss: 1.7727 - val_accuracy: 0.7373\n",
      "Epoch 72/250\n",
      "151/151 [==============================] - 4s 28ms/step - loss: 0.9393 - accuracy: 0.7895 - val_loss: 1.7701 - val_accuracy: 0.7368\n",
      "Epoch 73/250\n",
      "151/151 [==============================] - 4s 27ms/step - loss: 0.9374 - accuracy: 0.7910 - val_loss: 1.7763 - val_accuracy: 0.7370\n",
      "Epoch 74/250\n",
      "151/151 [==============================] - 4s 27ms/step - loss: 0.9338 - accuracy: 0.7910 - val_loss: 1.7657 - val_accuracy: 0.7369\n",
      "Epoch 75/250\n",
      "151/151 [==============================] - 4s 27ms/step - loss: 0.9302 - accuracy: 0.7915 - val_loss: 1.7890 - val_accuracy: 0.7365\n",
      "Epoch 76/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.9250 - accuracy: 0.7932 - val_loss: 1.7806 - val_accuracy: 0.7367\n",
      "Epoch 77/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.9204 - accuracy: 0.7919 - val_loss: 1.7864 - val_accuracy: 0.7365\n",
      "Epoch 78/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.9188 - accuracy: 0.7941 - val_loss: 1.7919 - val_accuracy: 0.7371\n",
      "Epoch 79/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.9168 - accuracy: 0.7929 - val_loss: 1.8047 - val_accuracy: 0.7354\n",
      "Epoch 80/250\n",
      "151/151 [==============================] - 4s 27ms/step - loss: 0.9149 - accuracy: 0.7940 - val_loss: 1.8039 - val_accuracy: 0.7345\n",
      "Epoch 81/250\n",
      "151/151 [==============================] - 4s 27ms/step - loss: 0.9106 - accuracy: 0.7955 - val_loss: 1.8145 - val_accuracy: 0.7359\n",
      "Epoch 82/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.9067 - accuracy: 0.7948 - val_loss: 1.8106 - val_accuracy: 0.7367\n",
      "Epoch 83/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.8984 - accuracy: 0.7953 - val_loss: 1.8059 - val_accuracy: 0.7361\n",
      "Epoch 84/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.8970 - accuracy: 0.7967 - val_loss: 1.8159 - val_accuracy: 0.7373\n",
      "Epoch 85/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.8950 - accuracy: 0.7966 - val_loss: 1.8302 - val_accuracy: 0.7355\n",
      "Epoch 86/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.8913 - accuracy: 0.7976 - val_loss: 1.8202 - val_accuracy: 0.7350\n",
      "Epoch 87/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.8907 - accuracy: 0.7965 - val_loss: 1.8340 - val_accuracy: 0.7360\n",
      "Epoch 88/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.8918 - accuracy: 0.7968 - val_loss: 1.8255 - val_accuracy: 0.7350\n",
      "Epoch 89/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.8835 - accuracy: 0.7989 - val_loss: 1.8392 - val_accuracy: 0.7341\n",
      "Epoch 90/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.8844 - accuracy: 0.7978 - val_loss: 1.8442 - val_accuracy: 0.7368\n",
      "Epoch 91/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.8740 - accuracy: 0.7995 - val_loss: 1.8326 - val_accuracy: 0.7349\n",
      "Epoch 92/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.8752 - accuracy: 0.8000 - val_loss: 1.8459 - val_accuracy: 0.7349\n",
      "Epoch 93/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.8744 - accuracy: 0.8006 - val_loss: 1.8480 - val_accuracy: 0.7354\n",
      "Epoch 94/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.8718 - accuracy: 0.8000 - val_loss: 1.8534 - val_accuracy: 0.7365\n",
      "Epoch 95/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.8658 - accuracy: 0.8018 - val_loss: 1.8655 - val_accuracy: 0.7379\n",
      "Epoch 96/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.8670 - accuracy: 0.8007 - val_loss: 1.8669 - val_accuracy: 0.7353\n",
      "Epoch 97/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.8588 - accuracy: 0.8021 - val_loss: 1.8564 - val_accuracy: 0.7358\n",
      "Epoch 98/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.8580 - accuracy: 0.8037 - val_loss: 1.8875 - val_accuracy: 0.7355\n",
      "Epoch 99/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.8576 - accuracy: 0.8032 - val_loss: 1.8790 - val_accuracy: 0.7350\n",
      "Epoch 100/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.8576 - accuracy: 0.8025 - val_loss: 1.8681 - val_accuracy: 0.7365\n",
      "Epoch 101/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.8512 - accuracy: 0.8040 - val_loss: 1.8858 - val_accuracy: 0.7351\n",
      "Epoch 102/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.8479 - accuracy: 0.8048 - val_loss: 1.8931 - val_accuracy: 0.7355\n",
      "Epoch 103/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.8477 - accuracy: 0.8038 - val_loss: 1.8811 - val_accuracy: 0.7345\n",
      "Epoch 104/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.8466 - accuracy: 0.8031 - val_loss: 1.8804 - val_accuracy: 0.7332\n",
      "Epoch 105/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.8417 - accuracy: 0.8047 - val_loss: 1.9106 - val_accuracy: 0.7345\n",
      "Epoch 106/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.8413 - accuracy: 0.8051 - val_loss: 1.9104 - val_accuracy: 0.7336\n",
      "Epoch 107/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.8351 - accuracy: 0.8057 - val_loss: 1.8866 - val_accuracy: 0.7326\n",
      "Epoch 108/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.8340 - accuracy: 0.8054 - val_loss: 1.9080 - val_accuracy: 0.7345\n",
      "Epoch 109/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.8339 - accuracy: 0.8067 - val_loss: 1.8983 - val_accuracy: 0.7332\n",
      "Epoch 110/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.8306 - accuracy: 0.8064 - val_loss: 1.9136 - val_accuracy: 0.7347\n",
      "Epoch 111/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.8285 - accuracy: 0.8106 - val_loss: 1.9103 - val_accuracy: 0.7341\n",
      "Epoch 112/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.8223 - accuracy: 0.8084 - val_loss: 1.9086 - val_accuracy: 0.7345\n",
      "Epoch 113/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.8232 - accuracy: 0.8078 - val_loss: 1.9221 - val_accuracy: 0.7329\n",
      "Epoch 114/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.8196 - accuracy: 0.8087 - val_loss: 1.9190 - val_accuracy: 0.7344\n",
      "Epoch 115/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.8196 - accuracy: 0.8094 - val_loss: 1.9175 - val_accuracy: 0.7336\n",
      "Epoch 116/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.8181 - accuracy: 0.8088 - val_loss: 1.9286 - val_accuracy: 0.7338\n",
      "Epoch 117/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.8095 - accuracy: 0.8098 - val_loss: 1.9389 - val_accuracy: 0.7351\n",
      "Epoch 118/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.8048 - accuracy: 0.8100 - val_loss: 1.9427 - val_accuracy: 0.7360\n",
      "Epoch 119/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.8091 - accuracy: 0.8092 - val_loss: 1.9220 - val_accuracy: 0.7336\n",
      "Epoch 120/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.8042 - accuracy: 0.8102 - val_loss: 1.9404 - val_accuracy: 0.7336\n",
      "Epoch 121/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.8030 - accuracy: 0.8106 - val_loss: 1.9512 - val_accuracy: 0.7336\n",
      "Epoch 122/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.8042 - accuracy: 0.8112 - val_loss: 1.9474 - val_accuracy: 0.7359\n",
      "Epoch 123/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.7981 - accuracy: 0.8137 - val_loss: 1.9629 - val_accuracy: 0.7351\n",
      "Epoch 124/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.7974 - accuracy: 0.8127 - val_loss: 1.9600 - val_accuracy: 0.7341\n",
      "Epoch 125/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.7926 - accuracy: 0.8130 - val_loss: 1.9665 - val_accuracy: 0.7355\n",
      "Epoch 126/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.7928 - accuracy: 0.8138 - val_loss: 1.9642 - val_accuracy: 0.7355\n",
      "Epoch 127/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.7928 - accuracy: 0.8143 - val_loss: 1.9616 - val_accuracy: 0.7337\n",
      "Epoch 128/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.7855 - accuracy: 0.8152 - val_loss: 1.9639 - val_accuracy: 0.7339\n",
      "Epoch 129/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.7870 - accuracy: 0.8147 - val_loss: 1.9800 - val_accuracy: 0.7352\n",
      "Epoch 130/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.7870 - accuracy: 0.8140 - val_loss: 1.9756 - val_accuracy: 0.7351\n",
      "Epoch 131/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.7835 - accuracy: 0.8158 - val_loss: 1.9768 - val_accuracy: 0.7351\n",
      "Epoch 132/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.7807 - accuracy: 0.8155 - val_loss: 1.9834 - val_accuracy: 0.7346\n",
      "Epoch 133/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.7776 - accuracy: 0.8160 - val_loss: 1.9917 - val_accuracy: 0.7369\n",
      "Epoch 134/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.7747 - accuracy: 0.8164 - val_loss: 1.9972 - val_accuracy: 0.7329\n",
      "Epoch 135/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.7763 - accuracy: 0.8154 - val_loss: 1.9912 - val_accuracy: 0.7332\n",
      "Epoch 136/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.7689 - accuracy: 0.8176 - val_loss: 2.0157 - val_accuracy: 0.7345\n",
      "Epoch 137/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.7739 - accuracy: 0.8179 - val_loss: 2.0030 - val_accuracy: 0.7335\n",
      "Epoch 138/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.7728 - accuracy: 0.8171 - val_loss: 2.0063 - val_accuracy: 0.7337\n",
      "Epoch 139/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.7740 - accuracy: 0.8165 - val_loss: 1.9927 - val_accuracy: 0.7341\n",
      "Epoch 140/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.7682 - accuracy: 0.8162 - val_loss: 1.9949 - val_accuracy: 0.7325\n",
      "Epoch 141/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.7633 - accuracy: 0.8185 - val_loss: 2.0085 - val_accuracy: 0.7322\n",
      "Epoch 142/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.7585 - accuracy: 0.8184 - val_loss: 2.0000 - val_accuracy: 0.7318\n",
      "Epoch 143/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.7611 - accuracy: 0.8186 - val_loss: 2.0092 - val_accuracy: 0.7337\n",
      "Epoch 144/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.7573 - accuracy: 0.8206 - val_loss: 2.0160 - val_accuracy: 0.7344\n",
      "Epoch 145/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.7545 - accuracy: 0.8190 - val_loss: 2.0097 - val_accuracy: 0.7345\n",
      "Epoch 146/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.7562 - accuracy: 0.8196 - val_loss: 2.0190 - val_accuracy: 0.7341\n",
      "Epoch 147/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.7537 - accuracy: 0.8202 - val_loss: 2.0332 - val_accuracy: 0.7338\n",
      "Epoch 148/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.7523 - accuracy: 0.8204 - val_loss: 2.0353 - val_accuracy: 0.7340\n",
      "Epoch 149/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.7529 - accuracy: 0.8203 - val_loss: 2.0292 - val_accuracy: 0.7336\n",
      "Epoch 150/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.7473 - accuracy: 0.8217 - val_loss: 2.0353 - val_accuracy: 0.7322\n",
      "Epoch 151/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.7468 - accuracy: 0.8212 - val_loss: 2.0221 - val_accuracy: 0.7311\n",
      "Epoch 152/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.7406 - accuracy: 0.8223 - val_loss: 2.0198 - val_accuracy: 0.7329\n",
      "Epoch 153/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.7394 - accuracy: 0.8220 - val_loss: 2.0384 - val_accuracy: 0.7323\n",
      "Epoch 154/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.7399 - accuracy: 0.8227 - val_loss: 2.0467 - val_accuracy: 0.7351\n",
      "Epoch 155/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.7374 - accuracy: 0.8228 - val_loss: 2.0613 - val_accuracy: 0.7338\n",
      "Epoch 156/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.7356 - accuracy: 0.8235 - val_loss: 2.0462 - val_accuracy: 0.7326\n",
      "Epoch 157/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.7328 - accuracy: 0.8237 - val_loss: 2.0679 - val_accuracy: 0.7325\n",
      "Epoch 158/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.7333 - accuracy: 0.8237 - val_loss: 2.0525 - val_accuracy: 0.7334\n",
      "Epoch 159/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.7307 - accuracy: 0.8236 - val_loss: 2.0555 - val_accuracy: 0.7341\n",
      "Epoch 160/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.7329 - accuracy: 0.8244 - val_loss: 2.0661 - val_accuracy: 0.7330\n",
      "Epoch 161/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.7258 - accuracy: 0.8243 - val_loss: 2.0573 - val_accuracy: 0.7326\n",
      "Epoch 162/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.7260 - accuracy: 0.8243 - val_loss: 2.0780 - val_accuracy: 0.7329\n",
      "Epoch 163/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.7272 - accuracy: 0.8246 - val_loss: 2.0722 - val_accuracy: 0.7326\n",
      "Epoch 164/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.7205 - accuracy: 0.8273 - val_loss: 2.0626 - val_accuracy: 0.7329\n",
      "Epoch 165/250\n",
      "151/151 [==============================] - 4s 25ms/step - loss: 0.7252 - accuracy: 0.8249 - val_loss: 2.1023 - val_accuracy: 0.7330\n",
      "Epoch 166/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.7244 - accuracy: 0.8238 - val_loss: 2.0707 - val_accuracy: 0.7331\n",
      "Epoch 167/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.7217 - accuracy: 0.8251 - val_loss: 2.1044 - val_accuracy: 0.7341\n",
      "Epoch 168/250\n",
      "151/151 [==============================] - 4s 30ms/step - loss: 0.7166 - accuracy: 0.8262 - val_loss: 2.0902 - val_accuracy: 0.7324\n",
      "Epoch 169/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.7163 - accuracy: 0.8275 - val_loss: 2.0969 - val_accuracy: 0.7335\n",
      "Epoch 170/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.7129 - accuracy: 0.8276 - val_loss: 2.1001 - val_accuracy: 0.7331\n",
      "Epoch 171/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.7149 - accuracy: 0.8272 - val_loss: 2.0975 - val_accuracy: 0.7344\n",
      "Epoch 172/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.7158 - accuracy: 0.8268 - val_loss: 2.1288 - val_accuracy: 0.7327\n",
      "Epoch 173/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.7119 - accuracy: 0.8285 - val_loss: 2.0941 - val_accuracy: 0.7336\n",
      "Epoch 174/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.7145 - accuracy: 0.8268 - val_loss: 2.0835 - val_accuracy: 0.7326\n",
      "Epoch 175/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.7114 - accuracy: 0.8280 - val_loss: 2.1323 - val_accuracy: 0.7334\n",
      "Epoch 176/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.7090 - accuracy: 0.8283 - val_loss: 2.0990 - val_accuracy: 0.7330\n",
      "Epoch 177/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.7055 - accuracy: 0.8284 - val_loss: 2.1083 - val_accuracy: 0.7328\n",
      "Epoch 178/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.7018 - accuracy: 0.8289 - val_loss: 2.1137 - val_accuracy: 0.7335\n",
      "Epoch 179/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.7024 - accuracy: 0.8295 - val_loss: 2.1009 - val_accuracy: 0.7331\n",
      "Epoch 180/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.7050 - accuracy: 0.8293 - val_loss: 2.0970 - val_accuracy: 0.7314\n",
      "Epoch 181/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.7016 - accuracy: 0.8298 - val_loss: 2.1357 - val_accuracy: 0.7321\n",
      "Epoch 182/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.6981 - accuracy: 0.8299 - val_loss: 2.1147 - val_accuracy: 0.7312\n",
      "Epoch 183/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.6974 - accuracy: 0.8306 - val_loss: 2.1276 - val_accuracy: 0.7315\n",
      "Epoch 184/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.6970 - accuracy: 0.8315 - val_loss: 2.1176 - val_accuracy: 0.7312\n",
      "Epoch 185/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.6954 - accuracy: 0.8301 - val_loss: 2.1362 - val_accuracy: 0.7316\n",
      "Epoch 186/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.6977 - accuracy: 0.8289 - val_loss: 2.1257 - val_accuracy: 0.7311\n",
      "Epoch 187/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.6923 - accuracy: 0.8307 - val_loss: 2.1264 - val_accuracy: 0.7319\n",
      "Epoch 188/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.6918 - accuracy: 0.8324 - val_loss: 2.1393 - val_accuracy: 0.7330\n",
      "Epoch 189/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.6867 - accuracy: 0.8333 - val_loss: 2.1508 - val_accuracy: 0.7325\n",
      "Epoch 190/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.6925 - accuracy: 0.8314 - val_loss: 2.1366 - val_accuracy: 0.7325\n",
      "Epoch 191/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.6898 - accuracy: 0.8321 - val_loss: 2.1361 - val_accuracy: 0.7317\n",
      "Epoch 192/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.6849 - accuracy: 0.8331 - val_loss: 2.1281 - val_accuracy: 0.7307\n",
      "Epoch 193/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.6856 - accuracy: 0.8324 - val_loss: 2.1527 - val_accuracy: 0.7327\n",
      "Epoch 194/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.6811 - accuracy: 0.8332 - val_loss: 2.1602 - val_accuracy: 0.7316\n",
      "Epoch 195/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.6797 - accuracy: 0.8325 - val_loss: 2.1530 - val_accuracy: 0.7321\n",
      "Epoch 196/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.6832 - accuracy: 0.8334 - val_loss: 2.1509 - val_accuracy: 0.7304\n",
      "Epoch 197/250\n",
      "151/151 [==============================] - 4s 27ms/step - loss: 0.6801 - accuracy: 0.8330 - val_loss: 2.1496 - val_accuracy: 0.7333\n",
      "Epoch 198/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.6782 - accuracy: 0.8333 - val_loss: 2.1707 - val_accuracy: 0.7320\n",
      "Epoch 199/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.6787 - accuracy: 0.8334 - val_loss: 2.1518 - val_accuracy: 0.7316\n",
      "Epoch 200/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.6748 - accuracy: 0.8342 - val_loss: 2.1536 - val_accuracy: 0.7315\n",
      "Epoch 201/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.6749 - accuracy: 0.8347 - val_loss: 2.1671 - val_accuracy: 0.7314\n",
      "Epoch 202/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.6685 - accuracy: 0.8358 - val_loss: 2.1599 - val_accuracy: 0.7314\n",
      "Epoch 203/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.6755 - accuracy: 0.8338 - val_loss: 2.1628 - val_accuracy: 0.7320\n",
      "Epoch 204/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.6716 - accuracy: 0.8347 - val_loss: 2.1507 - val_accuracy: 0.7321\n",
      "Epoch 205/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.6704 - accuracy: 0.8344 - val_loss: 2.1636 - val_accuracy: 0.7321\n",
      "Epoch 206/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.6696 - accuracy: 0.8360 - val_loss: 2.1814 - val_accuracy: 0.7319\n",
      "Epoch 207/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.6695 - accuracy: 0.8357 - val_loss: 2.1535 - val_accuracy: 0.7315\n",
      "Epoch 208/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.6659 - accuracy: 0.8367 - val_loss: 2.1663 - val_accuracy: 0.7330\n",
      "Epoch 209/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.6650 - accuracy: 0.8363 - val_loss: 2.1724 - val_accuracy: 0.7312\n",
      "Epoch 210/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.6666 - accuracy: 0.8354 - val_loss: 2.1707 - val_accuracy: 0.7325\n",
      "Epoch 211/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.6679 - accuracy: 0.8358 - val_loss: 2.1629 - val_accuracy: 0.7313\n",
      "Epoch 212/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.6628 - accuracy: 0.8372 - val_loss: 2.1785 - val_accuracy: 0.7309\n",
      "Epoch 213/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.6614 - accuracy: 0.8358 - val_loss: 2.1870 - val_accuracy: 0.7306\n",
      "Epoch 214/250\n",
      "151/151 [==============================] - 4s 28ms/step - loss: 0.6592 - accuracy: 0.8363 - val_loss: 2.1674 - val_accuracy: 0.7314\n",
      "Epoch 215/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.6606 - accuracy: 0.8369 - val_loss: 2.1849 - val_accuracy: 0.7316\n",
      "Epoch 216/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.6610 - accuracy: 0.8382 - val_loss: 2.1717 - val_accuracy: 0.7295\n",
      "Epoch 217/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.6545 - accuracy: 0.8377 - val_loss: 2.1593 - val_accuracy: 0.7316\n",
      "Epoch 218/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.6589 - accuracy: 0.8379 - val_loss: 2.1847 - val_accuracy: 0.7290\n",
      "Epoch 219/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.6577 - accuracy: 0.8363 - val_loss: 2.1929 - val_accuracy: 0.7301\n",
      "Epoch 220/250\n",
      "151/151 [==============================] - 4s 30ms/step - loss: 0.6538 - accuracy: 0.8386 - val_loss: 2.1914 - val_accuracy: 0.7298\n",
      "Epoch 221/250\n",
      "151/151 [==============================] - 4s 30ms/step - loss: 0.6583 - accuracy: 0.8374 - val_loss: 2.1888 - val_accuracy: 0.7304\n",
      "Epoch 222/250\n",
      "151/151 [==============================] - 4s 29ms/step - loss: 0.6553 - accuracy: 0.8377 - val_loss: 2.1902 - val_accuracy: 0.7297\n",
      "Epoch 223/250\n",
      "151/151 [==============================] - 4s 28ms/step - loss: 0.6495 - accuracy: 0.8394 - val_loss: 2.2059 - val_accuracy: 0.7321\n",
      "Epoch 224/250\n",
      "151/151 [==============================] - 4s 27ms/step - loss: 0.6529 - accuracy: 0.8381 - val_loss: 2.2057 - val_accuracy: 0.7304\n",
      "Epoch 225/250\n",
      "151/151 [==============================] - 4s 27ms/step - loss: 0.6478 - accuracy: 0.8386 - val_loss: 2.2078 - val_accuracy: 0.7321\n",
      "Epoch 226/250\n",
      "151/151 [==============================] - 4s 27ms/step - loss: 0.6517 - accuracy: 0.8386 - val_loss: 2.1878 - val_accuracy: 0.7321\n",
      "Epoch 227/250\n",
      "151/151 [==============================] - 4s 27ms/step - loss: 0.6494 - accuracy: 0.8381 - val_loss: 2.2079 - val_accuracy: 0.7311\n",
      "Epoch 228/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.6472 - accuracy: 0.8396 - val_loss: 2.2261 - val_accuracy: 0.7313\n",
      "Epoch 229/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.6492 - accuracy: 0.8390 - val_loss: 2.2023 - val_accuracy: 0.7310\n",
      "Epoch 230/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.6412 - accuracy: 0.8404 - val_loss: 2.2073 - val_accuracy: 0.7300\n",
      "Epoch 231/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.6453 - accuracy: 0.8396 - val_loss: 2.2007 - val_accuracy: 0.7304\n",
      "Epoch 232/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.6394 - accuracy: 0.8398 - val_loss: 2.2249 - val_accuracy: 0.7292\n",
      "Epoch 233/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.6442 - accuracy: 0.8412 - val_loss: 2.2123 - val_accuracy: 0.7316\n",
      "Epoch 234/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.6395 - accuracy: 0.8407 - val_loss: 2.2283 - val_accuracy: 0.7310\n",
      "Epoch 235/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.6376 - accuracy: 0.8411 - val_loss: 2.2290 - val_accuracy: 0.7314\n",
      "Epoch 236/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.6354 - accuracy: 0.8437 - val_loss: 2.2489 - val_accuracy: 0.7307\n",
      "Epoch 237/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.6390 - accuracy: 0.8416 - val_loss: 2.2159 - val_accuracy: 0.7307\n",
      "Epoch 238/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.6388 - accuracy: 0.8405 - val_loss: 2.2364 - val_accuracy: 0.7303\n",
      "Epoch 239/250\n",
      "151/151 [==============================] - 4s 27ms/step - loss: 0.6397 - accuracy: 0.8410 - val_loss: 2.2333 - val_accuracy: 0.7296\n",
      "Epoch 240/250\n",
      "151/151 [==============================] - 4s 29ms/step - loss: 0.6349 - accuracy: 0.8425 - val_loss: 2.2143 - val_accuracy: 0.7292\n",
      "Epoch 241/250\n",
      "151/151 [==============================] - 4s 28ms/step - loss: 0.6369 - accuracy: 0.8413 - val_loss: 2.2311 - val_accuracy: 0.7310\n",
      "Epoch 242/250\n",
      "151/151 [==============================] - 4s 27ms/step - loss: 0.6318 - accuracy: 0.8433 - val_loss: 2.2330 - val_accuracy: 0.7308\n",
      "Epoch 243/250\n",
      "151/151 [==============================] - 4s 27ms/step - loss: 0.6351 - accuracy: 0.8427 - val_loss: 2.2181 - val_accuracy: 0.7287\n",
      "Epoch 244/250\n",
      "151/151 [==============================] - 4s 26ms/step - loss: 0.6292 - accuracy: 0.8418 - val_loss: 2.2342 - val_accuracy: 0.7287\n",
      "Epoch 245/250\n",
      "151/151 [==============================] - 4s 27ms/step - loss: 0.6327 - accuracy: 0.8421 - val_loss: 2.2192 - val_accuracy: 0.7295\n",
      "Epoch 246/250\n",
      "151/151 [==============================] - 4s 28ms/step - loss: 0.6280 - accuracy: 0.8445 - val_loss: 2.2477 - val_accuracy: 0.7309\n",
      "Epoch 247/250\n",
      "151/151 [==============================] - 4s 27ms/step - loss: 0.6292 - accuracy: 0.8435 - val_loss: 2.2492 - val_accuracy: 0.7301\n",
      "Epoch 248/250\n",
      "151/151 [==============================] - 4s 27ms/step - loss: 0.6305 - accuracy: 0.8426 - val_loss: 2.2359 - val_accuracy: 0.7317\n",
      "Epoch 249/250\n",
      "151/151 [==============================] - 4s 27ms/step - loss: 0.6263 - accuracy: 0.8440 - val_loss: 2.2474 - val_accuracy: 0.7285\n",
      "Epoch 250/250\n",
      "151/151 [==============================] - 4s 27ms/step - loss: 0.6256 - accuracy: 0.8438 - val_loss: 2.2430 - val_accuracy: 0.7297\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(\n",
    "    [encoder_input_sequences, decoder_input_sequences],\n",
    "    decoder_targets,\n",
    "    epochs=250,\n",
    "    validation_split=0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "epoch_count = range(1, len(hist.history['accuracy']) + 1)\n",
    "sns.lineplot(x=epoch_count,  y=hist.history['accuracy'], label='train')\n",
    "sns.lineplot(x=epoch_count,  y=hist.history['val_accuracy'], label='valid')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zbwn0ekDy_s2",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 5 - Inferencia\n",
    "Experimentar el funcionamiento de su modelo. Recuerde que debe realizar la inferencia de los modelos por separado de encoder y decoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [
    "# Armar lo conversores de indice a palabra:\n",
    "idx2word_input = {v:k for k, v in word2idx_inputs.items()}\n",
    "idx2word_target = {v:k for k, v in word2idx_outputs.items()}"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "def answer_question(input_seq):\n",
    "    # Se transforma la sequencia de entrada a los stados \"h\" y \"c\" de la LSTM\n",
    "    # para enviar la primera vez al decoder\"\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Se inicializa la secuencia de entrada al decoder como \"<sos>\"\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    target_seq[0, 0] = word2idx_outputs[\"<sos>\"]\n",
    "\n",
    "    # Se obtiene el indice que finaliza la inferencia\n",
    "    eos = word2idx_outputs[\"<eos>\"]\n",
    "\n",
    "    output_sentence = []\n",
    "    for _ in range(max_out_len):\n",
    "        # Predicción del próximo elemento\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
    "        idx = np.argmax(output_tokens[0, 0, :])\n",
    "\n",
    "        # Si es \"end of sentece <eos>\" se acaba\n",
    "        if eos == idx:\n",
    "            break\n",
    "\n",
    "        # Transformar ídx a palabra\n",
    "        word = ''\n",
    "        if idx > 0:\n",
    "            word = idx2word_target[idx]\n",
    "            output_sentence.append(word)\n",
    "\n",
    "        # Actualizar los estados dado la ultimo prediccion\n",
    "        states_value = [h, c]\n",
    "\n",
    "        # Actualizar secuencia de entrada con la salida (re-alimentacion)\n",
    "        target_seq[0, 0] = idx\n",
    "\n",
    "    return ' '.join(output_sentence)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "-\n",
      "Input: hlo\n",
      "Response: hello how are you\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "-\n",
      "Input:  \n",
      "Response: i love to read\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "-\n",
      "Input: hi\n",
      "Response: hello how are you\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "-\n",
      "Input: what about you \n",
      "Response: i am not sure what you mean\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "-\n",
      "Input: labrador\n",
      "Response: what do you do for a living\n"
     ]
    }
   ],
   "source": [
    "for t in range(5):\n",
    "  i = np.random.choice(len(input_sentences))\n",
    "  input_seq = encoder_input_sequences[i:i+1]\n",
    "  translation = answer_question(input_seq)\n",
    "  print('-')\n",
    "  print('Input:', input_sentences[i])\n",
    "  print('Response:', translation)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "text_list = []\n",
    "text_list.append(\"Hi\")\n",
    "text_list.append(\"How are you\")\n",
    "text_list.append(\"What is your name?\")\n",
    "text_list.append(\"How old are you?\")\n",
    "text_list.append(\"Are you an IA?\")\n",
    "text_list.append(\"Are you intelligent?\")\n",
    "text_list.append(\"Do you have friends?\")\n",
    "text_list.append(\"see you later\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "-\n",
      "Input: Hi\n",
      "Response: hello how are you\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "-\n",
      "Input: How are you\n",
      "Response: i am fine\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "-\n",
      "Input: What is your name?\n",
      "Response: i am a teacher\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "-\n",
      "Input: How old are you?\n",
      "Response: i am 32 i am 32\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "-\n",
      "Input: Are you an IA?\n",
      "Response: i am not sure what you mean\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "-\n",
      "Input: Are you intelligent?\n",
      "Response: i am a teacher i am a girl\n",
      "1/1 [==============================] - 0s 9ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 11ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "-\n",
      "Input: Do you have friends?\n",
      "Response: i do not have any\n",
      "1/1 [==============================] - 0s 10ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 12ms/step\n",
      "-\n",
      "Input: see you later\n",
      "Response: i like to play video games\n"
     ]
    }
   ],
   "source": [
    "for t in range(len(text_list)):\n",
    "  integer_seq_test = input_tokenizer.texts_to_sequences(text_list)[t]\n",
    "  encoder_sequence_test = pad_sequences([integer_seq_test], maxlen=max_input_len)\n",
    "  translation = answer_question(encoder_sequence_test)\n",
    "  print('-')\n",
    "  print('Input:', text_list[t])\n",
    "  print('Response:', translation)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}