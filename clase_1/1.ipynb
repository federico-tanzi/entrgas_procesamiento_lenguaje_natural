{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "Ue5hxxkdAQJg",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<img src=\"https://github.com/FIUBA-Posgrado-Inteligencia-Artificial/procesamiento_lenguaje_natural/raw/main/logoFIUBA.jpg\" width=\"500\" align=\"center\">\n",
    "\n",
    "\n",
    "# Procesamiento de lenguaje natural\n",
    "## Vectorización\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "kCED1hh-Ioyf",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "PUbfVnzIIoMj",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * (np.linalg.norm(b)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DMOa4JPSCJ29",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "RIO7b8GjAC17",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "corpus = np.array(['que dia es hoy', 'martes el dia de hoy es martes', 'martes muchas gracias'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8WqdaTmO8P1r",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Documento 1 --> que dia es hoy \\\n",
    "Documento 2 --> martes el dia de hoy es martes \\\n",
    "Documento 3 --> martes muchas gracias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FVHxBRNzCMOS",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 1 - Obtener el vocabulario del corpus (los términos utilizados)\n",
    "- Cada documento transformarlo en una lista de términos\n",
    "- Armar un vector de términos no repetidos de todos los documentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "3ZqTOZzDI7uv",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['es', 'dia', 'de', 'el', 'gracias', 'muchas', 'hoy', 'que', 'martes']\n"
     ]
    }
   ],
   "source": [
    "terms = [doc.split() for doc in corpus]\n",
    "terms_flattened = [term for sublist in terms for term in sublist]\n",
    "unique_terms = list(set(terms_flattened))\n",
    "print(unique_terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RUhH983FI7It",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 2- OneHot encoding\n",
    "Data una lista de textos, devolver una matriz con la representación oneHotEncoding de estos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "Os0AAQo6I6Z1",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 0. 0. 0. 0. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 0. 0. 1. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 1. 0. 0. 1.]]\n",
      "Using scikit-learn\n",
      "[[0 1 0 1 0 1 0 0 1]\n",
      " [1 1 1 1 0 1 1 0 0]\n",
      " [0 0 0 0 1 0 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "matrix = np.zeros((len(corpus), len(unique_terms)))\n",
    "\n",
    "for i, doc in enumerate(corpus):\n",
    "    palabras_doc = doc.lower().split()\n",
    "    for j, termino in enumerate(unique_terms):\n",
    "        matrix[i, j] = int(termino in palabras_doc)\n",
    "\n",
    "print(matrix)\n",
    "\n",
    "print(\"Using scikit-learn\")\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(binary=True)\n",
    "\n",
    "matrix = vectorizer.fit_transform(corpus)\n",
    "\n",
    "matrix = matrix.toarray()\n",
    "\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IIyWGmCpJVQL",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 3- Vectores de frecuencia\n",
    "Data una lista de textos, devolver una matriz con la representación de frecuencia de estos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "yqij_7eHJbUi",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 0. 0. 0. 0. 1. 1. 0.]\n",
      " [1. 1. 1. 1. 0. 0. 1. 0. 2.]\n",
      " [0. 0. 0. 0. 1. 1. 0. 0. 1.]]\n",
      "Using scikit-learn\n",
      "[[0 1 0 1 0 1 0 0 1]\n",
      " [1 1 1 1 0 1 2 0 0]\n",
      " [0 0 0 0 1 0 1 1 0]]\n"
     ]
    }
   ],
   "source": [
    "matrix = np.zeros((len(corpus), len(unique_terms)))\n",
    "\n",
    "for i, texto in enumerate(corpus):\n",
    "    terms = texto.split()\n",
    "    for j, term in enumerate(unique_terms):\n",
    "        matrix[i, j] = terms.count(term)\n",
    "\n",
    "print(matrix)\n",
    "\n",
    "print(\"Using scikit-learn\")\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "matrix = vectorizer.fit_transform(corpus)\n",
    "\n",
    "matrix = matrix.toarray()\n",
    "\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z_Ot8HvWJcBu",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 4- TF-IDF\n",
    "Data una lista de textos, devolver una matriz con la representacion TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "waG_oWtpJjRw",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.45985353 0.45985353 0.         0.         0.         0.\n",
      "  0.45985353 0.60465213 0.        ]\n",
      " [0.30922846 0.30922846 0.40659827 0.40659827 0.         0.\n",
      "  0.30922846 0.         0.61845693]\n",
      " [0.         0.         0.         0.         0.62276601 0.62276601\n",
      "  0.         0.         0.4736296 ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(vocabulary=unique_terms)\n",
    "\n",
    "matrix = vectorizer.fit_transform(corpus)\n",
    "\n",
    "matrix = matrix.toarray()\n",
    "\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xMcsfndWJjm_",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 5 - Comparación de documentos\n",
    "Realizar una funcion que reciba el corpus y el índice de un documento y devuelva los documentos ordenados por la similitud coseno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "CZdiop6IJpZN",
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['que dia es hoy', 'martes el dia de hoy es martes', 'martes muchas gracias']\n"
     ]
    }
   ],
   "source": [
    "def order_by_cosine_similarity(corpus, index):\n",
    "    vectorizador = TfidfVectorizer()\n",
    "    matriz_tfidf = vectorizador.fit_transform(corpus).toarray()\n",
    "        # Calcular la similitud de coseno entre el documento de referencia y los demás documentos\n",
    "    similitudes = []\n",
    "    for i in range(len(corpus)):\n",
    "        similitud = cosine_similarity(matriz_tfidf[index], matriz_tfidf[i])\n",
    "        similitudes.append(similitud)\n",
    "\n",
    "    # Ordenar los documentos según la similitud de coseno\n",
    "    documentos_ordenados = [x for _, x in sorted(zip(similitudes, corpus), reverse=True)]\n",
    "\n",
    "    return documentos_ordenados\n",
    "\n",
    "\n",
    "print(order_by_cosine_similarity(corpus, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO5fRYTpympAwJSVbric6dW",
   "collapsed_sections": [],
   "name": "1a - word2vec.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}